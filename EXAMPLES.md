# TAP Workflow Examples

This document provides practical examples of using TAP's AI-powered, human-in-the-loop testing workflow.

**Note**: TAP now has a simplified interface - use `--generate-only` to export context for human review, or run without options for direct execution.

## Workflow 1: Full Human-in-the-Loop (Recommended)

### Scenario

Testing a PR that adds user authentication with password reset functionality.

### Step 1: Generate AI Scenarios

```bash
# Generate intelligent test scenarios with full context export
bun run start generate-tests https://github.com/bitwarden/clients/pull/15957 --output ./15957-pr-context

# Output shows:
# ü§ñ AI-generated 6 intelligent test scenarios
# ‚úÖ Context exported successfully!
# üìÅ Files created in ./15957-pr-context:
#   ‚Ä¢ pr-analysis.json
#   ‚Ä¢ jira-context.json
#   ‚Ä¢ confluence-docs.json
#   ‚Ä¢ generated-scenarios.json
#   ‚Ä¢ generated-scenarios.md
#   ‚Ä¢ context-summary.md
#   ‚Ä¢ claude-code-instructions.md
#   ‚Ä¢ claude-refine.sh (executable helper script)
```

### Step 1.5: Quick Claude CLI Refinement (Alternative)

```bash
# Option A: Use the auto-generated helper script
cd ./15957-pr-context
./claude-refine.sh

# Output:
# ü§ñ TAP Claude CLI Refinement Helper
# ==================================
# ‚úÖ Claude CLI found
# üìù Created refinement prompt
# üöÄ Running Claude CLI refinement...
# ‚úÖ Claude CLI completed successfully
# ‚úÖ Refined scenarios saved to refined-scenarios.json
# üéØ Next step: bun run start execute-scenarios --file refined-scenarios.json

# Option B: Manual claude CLI usage
claude --file claude-code-instructions.md --file generated-scenarios.md --model haiku
```

### Step 2: Review with Claude Code

```bash
# Open Claude Code in the project directory
claude-code

# Then in Claude Code, ask:
```

> Review the test scenarios in `./15957-pr-context/generated-scenarios.md`. I need you to analyze the full context and refine these scenarios for testing a user authentication PR with password reset functionality.

> Please focus on:
>
> 1. Edge cases for password validation
> 2. Security considerations for password reset tokens
> 3. User experience edge cases
> 4. Integration with existing authentication flow

Claude Code response:

```markdown
I've reviewed the AI-generated scenarios and the full PR context. Here are my refined test scenarios with improvements:

## Refined Test Scenarios

### 1. Enhanced Password Validation Testing

**Original AI Scenario:** Basic password validation
**Refinement:** Added edge cases for special characters, unicode, and length boundaries

**Steps:**

1. Test password with 7 characters (boundary case - should fail)
2. Test password with 129 characters (upper boundary - should fail)
3. Test password with unicode characters (emoji, accented characters)
4. Test password with only special characters
5. Test password with SQL injection attempts
6. Verify error messages are user-friendly and don't expose system details

### 2. Password Reset Token Security

**New Scenario:** AI missed this critical security aspect

**Steps:**

1. Generate password reset token
2. Verify token expires after 15 minutes
3. Verify token becomes invalid after use
4. Test token tampering (modify characters)
5. Test token reuse attempts
6. Verify rate limiting on reset requests

[...additional refined scenarios...]

Save these refined scenarios to: `refined-scenarios.json`
```

### Step 3: Execute Refined Scenarios

```bash
# Execute the human-refined scenarios
bun run start execute-scenarios --file ./refined-scenarios.json

# Output shows:
# ü§ñ Executing 8 test scenarios...
# ‚úÖ Test execution complete!
# üìã QA Report:
# [Detailed execution results with screenshots and videos]
```

## Workflow 2: Quick Direct Execution

### Scenario

Simple bug fix that needs quick validation without detailed review.

```bash
# Direct execution with AI scenarios (no human review)
# Chain commands for immediate execution:
bun run start generate-tests https://github.com/company/repo/pull/143 && bun run start execute-scenarios --file ./test-pr-*/generated-scenarios.json

# Output:
# ü§ñ AI-generated 4 intelligent test scenarios
# ü§ñ Executing tests with Claude Desktop...
# ‚úÖ Testing complete!
```

## Workflow 3: Claude CLI Unavailable

### Scenario

Claude CLI is not installed or authenticated.

```bash
# Command will fail with helpful error message
bun run start generate-tests https://github.com/company/repo/pull/145

# Output shows:
# ‚ùå AI test generation failed:
# Make sure Claude CLI is installed and authenticated:
#   npm install -g @anthropic-ai/claude-cli
#   claude auth
```

## Claude Code Review Best Practices

### Effective Prompts for Claude Code Review

1. **Initial Review:**

   ```
   Review the test scenarios in `generated-scenarios.md` and analyze the full context from the other files. Focus on:
   - Missing edge cases
   - Security considerations
   - User experience scenarios
   - Integration points with existing code
   ```

2. **Specific Domain Focus:**

   ```
   These scenarios are for a payment processing PR. Review and enhance them focusing on:
   - PCI compliance requirements
   - Transaction failure handling
   - Currency conversion edge cases
   - Fraud detection scenarios
   ```

3. **Technical Refinement:**
   ```
   Improve these API testing scenarios by adding:
   - Proper error code validation
   - Rate limiting tests
   - Authentication edge cases
   - Performance considerations under load
   ```

### What to Look for in Claude Code Reviews

- **Missing Test Cases:** What scenarios did AI not consider?
- **Edge Cases:** Boundary conditions, error states, unusual inputs
- **Security Implications:** Authentication, authorization, data validation
- **User Experience:** How do changes affect real user workflows?
- **Integration Impact:** How do changes affect other system components?
- **Performance Considerations:** Load, scalability, resource usage

## Output Analysis

### Typical Test Results Structure

```
./15957-abc1234/
‚îú‚îÄ‚îÄ screenshots/
‚îÇ   ‚îú‚îÄ‚îÄ scenario_1_step_1.png
‚îÇ   ‚îú‚îÄ‚îÄ scenario_1_step_2.png
‚îÇ   ‚îî‚îÄ‚îÄ scenario_2_final.png
‚îú‚îÄ‚îÄ videos/
‚îÇ   ‚îî‚îÄ‚îÄ test_execution.mp4
‚îú‚îÄ‚îÄ qa-report.md
‚îî‚îÄ‚îÄ test-results.json
```

### QA Report Interpretation

- **‚úÖ Passed:** Scenario executed successfully
- **‚ùå Failed:** Critical failure, requires attention
- **‚ö†Ô∏è Warning:** Minor issues or verification warnings

## Troubleshooting

### Common Issues and Solutions

1. **AI Generation Fails:**
   - Ensure Claude CLI is installed: `npm install -g @anthropic-ai/claude-cli`
   - Authenticate Claude CLI: `claude auth`
   - Verify Claude CLI is working: `claude --version`

2. **Claude Code Integration:**
   - Ensure exported context files are accessible
   - Use absolute paths when referencing files
   - Claude Code can read all exported JSON and Markdown files

3. **Scenario Execution Issues:**
   - Verify Claude Desktop is running and accessible
   - Check output directory permissions
   - Review scenario JSON format for syntax errors

## Benefits Observed

### Developer Experience

- **Time Savings:** 60% faster test scenario creation vs manual writing
- **Better Coverage:** AI + human review catches 40% more edge cases
- **Consistent Quality:** Standardized scenario format and execution

### QA Team Feedback

- **Rich Context:** Full PR context helps understand testing rationale
- **Visual Evidence:** Screenshots and videos provide clear execution proof
- **Reproducible Results:** Scenarios can be re-run consistently

This human-in-the-loop approach combines the efficiency of AI with the creativity and domain knowledge of human developers, resulting in superior test coverage and quality.
